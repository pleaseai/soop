#!/usr/bin/env node
import type { SemanticOptions } from '@pleaseai/rpg-encoder/semantic'
import type { SerializedEmbeddings } from '@pleaseai/rpg-graph/embeddings'

import { readFile, writeFile } from 'node:fs/promises'
import path from 'node:path'
import { RPGEncoder } from '@pleaseai/rpg-encoder'
import { RepositoryPlanningGraph } from '@pleaseai/rpg-graph'
import { serializeEmbeddings } from '@pleaseai/rpg-graph/embeddings'
import { ExploreRPG, FetchNode, SearchNode } from '@pleaseai/rpg-tools'
import { getHeadCommitSha } from '@pleaseai/rpg-utils/git-helpers'
import { parseModelString } from '@pleaseai/rpg-utils/llm'
import { createLogger, LogLevels, setLogLevel } from '@pleaseai/rpg-utils/logger'
import { ZeroRepo } from '@pleaseai/rpg-zerorepo'
import { program } from 'commander'
import { config } from 'dotenv'

import pkg from '../package.json'
import { registerInitCommand } from './commands/init'
import { registerSyncCommand } from './commands/sync'

const log = createLogger('CLI')

config({ path: ['.env.local', '.env'] })

program
  .name('rpg')
  .description('Repository Planning Graph - Code understanding and generation')
  .version(pkg.version)

// Register subcommands
registerInitCommand(program)
registerSyncCommand(program)

// Encode command
program
  .command('encode')
  .description('Encode a repository into an RPG')
  .argument('<path>', 'Repository path')
  .option('-o, --output <file>', 'Output file path', 'rpg.json')
  .option('--include-source', 'Include source code in nodes')
  .option('-i, --include <patterns...>', 'Include file patterns (default: **/*.ts,**/*.js,**/*.py)')
  .option(
    '-e, --exclude <patterns...>',
    'Exclude file patterns (default: **/node_modules/**,**/dist/**)',
  )
  .option('-d, --max-depth <depth>', 'Maximum directory depth', '10')
  .option('--no-gitignore', 'Disable .gitignore filtering (include all files)')
  .option('-m, --model <provider/model>', 'LLM provider/model (e.g., codex/gpt-5.3-codex, claude-code/haiku, openai/gpt-5.2, google)')
  .option('--no-llm', 'Disable LLM (use heuristic extraction)')
  .option('--stamp', 'Stamp config.github.commit with HEAD SHA after encoding')
  .option('--embed', 'Generate embeddings file after encoding')
  .option('--embed-model <provider/model>', 'Embedding provider/model (default: voyage-ai/voyage-code-3)')
  .option('--embed-output <path>', 'Embeddings output file path', '.rpg/embeddings.json')
  .option('--verbose', 'Show detailed progress')
  .option('--min-batch-tokens <tokens>', 'Minimum tokens per batch (default: 10000)')
  .option('--max-batch-tokens <tokens>', 'Maximum tokens per batch (default: 50000)')
  .action(
    async (
      repoPath: string,
      options: {
        output: string
        includeSource?: boolean
        include?: string[]
        exclude?: string[]
        maxDepth: string
        gitignore?: boolean
        model?: string
        llm?: boolean
        stamp?: boolean
        embed?: boolean
        embedModel?: string
        embedOutput: string
        verbose?: boolean
        minBatchTokens?: string
        maxBatchTokens?: string
      },
    ) => {
      if (options.verbose) {
        setLogLevel(LogLevels.debug)
      }

      const semantic = buildSemanticOptions(options.model, options.llm, options.minBatchTokens, options.maxBatchTokens)

      log.info(`Encoding repository: ${repoPath}`)
      log.debug(
        `  Include patterns: ${options.include?.join(', ') || '**/*.ts,**/*.js,**/*.py'}`,
      )
      log.debug(
        `  Exclude patterns: ${options.exclude?.join(', ') || '**/node_modules/**,**/dist/**'}`,
      )
      log.debug(`  Max depth: ${options.maxDepth}`)

      const encoder = new RPGEncoder(repoPath, {
        includeSource: options.includeSource,
        include: options.include,
        exclude: options.exclude,
        maxDepth: Number.parseInt(options.maxDepth),
        respectGitignore: options.gitignore !== false,
        semantic,
      })

      const result = await encoder.encode()

      const headSha = options.stamp || options.embed
        ? stampRpgWithHead(result.rpg, repoPath)
        : undefined
      if (options.stamp && headSha) {
        log.info(`Stamped commit: ${headSha}`)
      }

      await writeFile(options.output, await result.rpg.toJSON())

      // Generate embeddings if requested
      if (options.embed) {
        const embeddings = await generateEmbeddings(
          result.rpg,
          headSha ?? getHeadCommitSha(path.resolve(repoPath)),
          options.embedModel,
        )
        await writeEmbeddingsFile(embeddings, options.embedOutput)
      }

      const stats = await result.rpg.getStats()

      console.log('\nEncoding complete:')
      console.log(`  Files processed: ${result.filesProcessed}`)
      console.log(`  Entities extracted: ${result.entitiesExtracted}`)
      console.log(`  Duration: ${result.duration}ms`)
      console.log(`  Output: ${options.output}`)

      if (options.verbose) {
        console.log('\nGraph statistics:')
        console.log(`  Total nodes: ${stats.nodeCount}`)
        console.log(`    High-level (modules): ${stats.highLevelNodeCount}`)
        console.log(`    Low-level (entities): ${stats.lowLevelNodeCount}`)
        console.log(`  Total edges: ${stats.edgeCount}`)
        console.log(`    Functional: ${stats.functionalEdgeCount}`)
        console.log(`    Dependency: ${stats.dependencyEdgeCount}`)
      }
    },
  )

// Generate command
program
  .command('generate')
  .description('Generate a repository from specification')
  .option('-s, --spec <spec>', 'Repository specification')
  .option('-f, --spec-file <file>', 'Specification file')
  .option('-o, --output <dir>', 'Output directory', './generated')
  .option('--no-tests', 'Skip test generation')
  .action(async (options: { spec?: string, specFile?: string, output: string, tests: boolean }) => {
    let spec = options.spec

    if (options.specFile) {
      spec = await readFile(options.specFile, 'utf-8')
    }

    if (!spec) {
      log.error('Either --spec or --spec-file is required')
      process.exit(1)
    }

    log.info('Generating repository...')
    log.info(`Specification: ${spec.substring(0, 100)}...`)

    const zerorepo = new ZeroRepo({
      spec,
      generateTests: options.tests,
    })

    const proposalGraph = await zerorepo.buildProposalGraph()
    const rpg = await zerorepo.buildImplementationGraph(proposalGraph)
    const result = await zerorepo.generateRepository(rpg, options.output)

    console.log('\nGeneration complete:')
    console.log(`  Files generated: ${result.filesGenerated}`)
    console.log(`  Lines of code: ${result.linesOfCode}`)
    console.log(`  Output: ${result.outputPath}`)
  })

// Search command
program
  .command('search')
  .description('Search for features or code in an RPG')
  .requiredOption('--rpg <file>', 'RPG file path')
  .option('-t, --term <term>', 'Search term')
  .option('-m, --mode <mode>', 'Search mode (features, snippets, auto)', 'auto')
  .option('-p, --pattern <pattern>', 'File pattern for snippet search')
  .action(async (options: { rpg: string, term?: string, mode: string, pattern?: string }) => {
    const json = await readFile(options.rpg, 'utf-8')
    const rpg = await RepositoryPlanningGraph.fromJSON(json)

    const search = new SearchNode(rpg)
    const results = await search.query({
      mode: options.mode as 'features' | 'snippets' | 'auto',
      featureTerms: options.term ? [options.term] : undefined,
      filePattern: options.pattern,
    })

    console.log(`\nSearch results (${results.totalMatches} matches):`)
    for (const node of results.nodes) {
      console.log(`\n  ID: ${node.id}`)
      console.log(`  Type: ${node.type}`)
      console.log(`  Feature: ${node.feature.description}`)
      if (node.metadata?.path) {
        console.log(`  Path: ${node.metadata.path}`)
      }
    }
  })

// Fetch command
program
  .command('fetch')
  .description('Fetch detailed information for entities')
  .requiredOption('--rpg <file>', 'RPG file path')
  .argument('<entities...>', 'Entity IDs to fetch')
  .action(async (entities: string[], options: { rpg: string }) => {
    const json = await readFile(options.rpg, 'utf-8')
    const rpg = await RepositoryPlanningGraph.fromJSON(json)

    const fetcher = new FetchNode(rpg)
    const results = await fetcher.get({ codeEntities: entities })

    console.log(`\nFetched ${results.entities.length} entities:`)
    for (const entity of results.entities) {
      console.log(`\n  ID: ${entity.node.id}`)
      console.log(`  Feature: ${entity.node.feature.description}`)
      console.log(`  Path: ${entity.featurePaths.join(' â†’ ')}`)
      if (entity.sourceCode) {
        console.log(`  Source:\n${entity.sourceCode.substring(0, 200)}...`)
      }
    }

    if (results.notFound.length > 0) {
      console.log(`\nNot found: ${results.notFound.join(', ')}`)
    }
  })

// Explore command
program
  .command('explore')
  .description('Explore graph from a starting node')
  .requiredOption('--rpg <file>', 'RPG file path')
  .argument('<node>', 'Starting node ID')
  .option('-e, --edge-type <type>', 'Edge type (containment, dependency, all)', 'all')
  .option('-d, --depth <depth>', 'Maximum depth', '3')
  .option('--direction <dir>', 'Direction (downstream, upstream, both)', 'downstream')
  .action(
    async (
      node: string,
      options: { rpg: string, edgeType: string, depth: string, direction: string },
    ) => {
      const json = await readFile(options.rpg, 'utf-8')
      const rpg = await RepositoryPlanningGraph.fromJSON(json)

      const explorer = new ExploreRPG(rpg)
      const results = await explorer.traverse({
        startNode: node,
        edgeType: options.edgeType as 'containment' | 'dependency' | 'all',
        maxDepth: Number.parseInt(options.depth),
        direction: options.direction as 'downstream' | 'upstream' | 'both',
      })

      console.log(`\nExploration from "${node}":`)
      console.log(`  Nodes discovered: ${results.nodes.length}`)
      console.log(`  Edges traversed: ${results.edges.length}`)
      console.log(`  Max depth reached: ${results.maxDepthReached}`)

      console.log('\nNodes:')
      for (const n of results.nodes) {
        console.log(`  - ${n.id}: ${n.feature.description}`)
      }
    },
  )

// Evolve command
program
  .command('evolve')
  .description('Update RPG with new commits')
  .requiredOption('--rpg <file>', 'RPG file path')
  .option('-c, --commits <range>', 'Commit range', 'HEAD~1..HEAD')
  .option('-m, --model <provider/model>', 'LLM provider/model (e.g., codex/gpt-5.3-codex, claude-code/haiku, openai/gpt-5.2, google)')
  .option('--no-llm', 'Disable LLM (use heuristic extraction)')
  .option('--stamp', 'Stamp config.github.commit with HEAD SHA')
  .option('--min-batch-tokens <tokens>', 'Minimum tokens per batch (default: 10000)')
  .option('--max-batch-tokens <tokens>', 'Maximum tokens per batch (default: 50000)')
  .action(async (options: { rpg: string, commits: string, model?: string, llm?: boolean, stamp?: boolean, minBatchTokens?: string, maxBatchTokens?: string }) => {
    log.info(`Evolving RPG with commits: ${options.commits}`)

    const json = await readFile(options.rpg, 'utf-8')
    const rpg = await RepositoryPlanningGraph.fromJSON(json)
    const repoPath = rpg.getConfig().rootPath ?? '.'

    const semantic = buildSemanticOptions(options.model, options.llm, options.minBatchTokens, options.maxBatchTokens)

    const encoder = new RPGEncoder(repoPath, { semantic })
    const result = await encoder.evolve(rpg, { commitRange: options.commits })

    if (options.stamp) {
      const headSha = stampRpgWithHead(rpg, repoPath)
      log.info(`Stamped commit: ${headSha}`)
    }

    await writeFile(options.rpg, await rpg.toJSON())

    console.log('\nEvolution complete:')
    console.log(`  Inserted: ${result.inserted}`)
    console.log(`  Modified: ${result.modified}`)
    console.log(`  Deleted: ${result.deleted}`)
    console.log(`  Rerouted: ${result.rerouted}`)
    console.log(`  Duration: ${result.duration}ms`)
    if (result.errors.length > 0) {
      log.warn(`Errors (${result.errors.length}):`)
      for (const err of result.errors) {
        log.warn(`  [${err.phase}] ${err.entity}: ${err.error}`)
      }
    }
  })

// Stats command
program
  .command('stats')
  .description('Show RPG statistics')
  .argument('<file>', 'RPG file path')
  .action(async (filePath: string) => {
    const json = await readFile(filePath, 'utf-8')
    const rpg = await RepositoryPlanningGraph.fromJSON(json)
    const stats = await rpg.getStats()
    const config = rpg.getConfig()

    console.log(`\nRPG Statistics for "${config.name}":`)
    console.log(`  Total nodes: ${stats.nodeCount}`)
    console.log(`    High-level: ${stats.highLevelNodeCount}`)
    console.log(`    Low-level: ${stats.lowLevelNodeCount}`)
    console.log(`  Total edges: ${stats.edgeCount}`)
    console.log(`    Functional: ${stats.functionalEdgeCount}`)
    console.log(`    Dependency: ${stats.dependencyEdgeCount}`)
  })

// Stamp command
program
  .command('stamp')
  .description('Stamp config.github.commit with current HEAD SHA')
  .argument('<file>', 'RPG file path')
  .action(async (filePath: string) => {
    const json = await readFile(filePath, 'utf-8')
    const rpg = await RepositoryPlanningGraph.fromJSON(json)
    const repoPath = rpg.getConfig().rootPath ?? '.'
    const headSha = stampRpgWithHead(rpg, repoPath)
    await writeFile(filePath, await rpg.toJSON())
    console.log(headSha)
  })

// Last-commit command
program
  .command('last-commit')
  .description('Print the last encoded commit SHA from config.github.commit')
  .argument('<file>', 'RPG file path')
  .action(async (filePath: string) => {
    const json = await readFile(filePath, 'utf-8')
    const rpg = await RepositoryPlanningGraph.fromJSON(json)
    const commit = rpg.getConfig().github?.commit
    if (!commit) {
      log.error('No commit stamp found in RPG config')
      process.exit(1)
    }
    console.log(commit)
  })

// Embed command (standalone)
program
  .command('embed')
  .description('Generate embeddings file from an RPG')
  .requiredOption('--rpg <file>', 'RPG file path')
  .option('--model <provider/model>', 'Embedding provider/model (default: voyage-ai/voyage-code-3)')
  .option('-o, --output <file>', 'Output file path', '.rpg/embeddings.json')
  .option('--stamp', 'Stamp embeddings commit with HEAD SHA')
  .action(
    async (options: {
      rpg: string
      model?: string
      output: string
      stamp?: boolean
    }) => {
      const json = await readFile(options.rpg, 'utf-8')
      const rpg = await RepositoryPlanningGraph.fromJSON(json)
      const repoPath = rpg.getConfig().rootPath ?? '.'

      const commitSha = options.stamp
        ? getHeadCommitSha(path.resolve(repoPath))
        : (rpg.getConfig().github?.commit ?? getHeadCommitSha(path.resolve(repoPath)))

      const embeddings = await generateEmbeddings(rpg, commitSha, options.model)
      await writeEmbeddingsFile(embeddings, options.output)
    },
  )

/**
 * Stamp RPG config with the current HEAD commit SHA.
 * Returns the stamped SHA.
 */
function stampRpgWithHead(rpg: RepositoryPlanningGraph, repoPath: string): string {
  const absRepoPath = path.resolve(repoPath)
  const headSha = getHeadCommitSha(absRepoPath)
  const currentConfig = rpg.getConfig()
  rpg.updateConfig({
    github: {
      owner: currentConfig.github?.owner ?? '',
      repo: currentConfig.github?.repo ?? currentConfig.name,
      commit: headSha,
      pathPrefix: currentConfig.github?.pathPrefix,
    },
  })
  return headSha
}

/**
 * Build SemanticOptions from CLI flags
 */
function buildSemanticOptions(
  model?: string,
  llm?: boolean,
  minBatchTokens?: string,
  maxBatchTokens?: string,
): SemanticOptions | undefined {
  const hasBatchOptions = minBatchTokens !== undefined || maxBatchTokens !== undefined
  if (!model && llm !== false && !hasBatchOptions) {
    return undefined
  }

  const parsedMin = minBatchTokens !== undefined ? Number.parseInt(minBatchTokens, 10) : undefined
  const parsedMax = maxBatchTokens !== undefined ? Number.parseInt(maxBatchTokens, 10) : undefined

  if (parsedMin !== undefined && (Number.isNaN(parsedMin) || parsedMin < 0)) {
    log.error(`Invalid --min-batch-tokens value: ${minBatchTokens}`)
    process.exit(1)
  }
  if (parsedMax !== undefined && (Number.isNaN(parsedMax) || parsedMax < 0)) {
    log.error(`Invalid --max-batch-tokens value: ${maxBatchTokens}`)
    process.exit(1)
  }
  if (parsedMin !== undefined && parsedMax !== undefined && parsedMin > parsedMax) {
    log.error(`--min-batch-tokens (${parsedMin}) cannot be greater than --max-batch-tokens (${parsedMax})`)
    process.exit(1)
  }

  return {
    ...(model ? parseModelString(model) : {}),
    useLLM: llm !== false,
    ...(parsedMin !== undefined ? { minBatchTokens: parsedMin } : {}),
    ...(parsedMax !== undefined ? { maxBatchTokens: parsedMax } : {}),
  }
}

/** Git LFS size warning threshold (10MB) */
const GIT_LFS_THRESHOLD = 10 * 1024 * 1024

/**
 * Generate embeddings for an RPG using the specified model.
 */
async function generateEmbeddings(
  rpg: RepositoryPlanningGraph,
  commit: string,
  embedModelStr?: string,
): Promise<SerializedEmbeddings> {
  const { EmbeddingManager } = await import('@pleaseai/rpg-encoder/embedding-manager')
  const { createOpenAI } = await import('@ai-sdk/openai')
  const { AISDKEmbedding } = await import('@pleaseai/rpg-encoder/embedding')

  const parsed = parseEmbedModelString(embedModelStr ?? 'voyage-ai/voyage-code-3')

  const provider = createOpenAI({
    baseURL: parsed.baseURL,
    apiKey: parsed.apiKey,
  })

  const embedding = new AISDKEmbedding({
    model: provider.embedding(parsed.model),
    dimension: parsed.dimension,
    providerName: parsed.providerName,
  })

  const manager = new EmbeddingManager(embedding, {
    provider: parsed.providerName,
    model: parsed.model,
    dimension: parsed.dimension,
    space: parsed.space,
  })

  return manager.indexAll(rpg, commit)
}

/**
 * Write embeddings to file with size warning.
 */
async function writeEmbeddingsFile(embeddings: SerializedEmbeddings, outputPath: string): Promise<void> {
  const content = serializeEmbeddings(embeddings)
  await writeFile(outputPath, content)

  const size = Buffer.byteLength(content)
  const sizeMB = (size / (1024 * 1024)).toFixed(1)
  log.success(`Embeddings written: ${outputPath} (${sizeMB}MB, ${embeddings.embeddings.length} nodes)`)

  if (size > GIT_LFS_THRESHOLD) {
    log.warn(`embeddings.json is ${sizeMB}MB. Consider using Git LFS:`)
    log.warn(`  git lfs track "${outputPath}"`)
  }
}

interface ParsedEmbedModel {
  providerName: string
  model: string
  baseURL: string
  apiKey: string
  dimension: number
  space?: string
}

/**
 * Parse embed model string like "voyage-ai/voyage-code-3" or "openai/text-embedding-3-small"
 */
function parseEmbedModelString(modelStr: string): ParsedEmbedModel {
  const [providerPart, ...modelParts] = modelStr.split('/')
  const model = modelParts.join('/') || providerPart!

  switch (providerPart) {
    case 'voyage-ai':
      return {
        providerName: 'VoyageAI',
        model,
        baseURL: 'https://api.voyageai.com/v1',
        apiKey: process.env.VOYAGE_API_KEY ?? '',
        dimension: 1024,
        space: 'voyage-v4',
      }
    case 'openai':
      return {
        providerName: 'OpenAI',
        model,
        baseURL: 'https://api.openai.com/v1',
        apiKey: process.env.OPENAI_API_KEY ?? '',
        dimension: model === 'text-embedding-3-large' ? 3072 : 1536,
      }
    default:
      return {
        providerName: providerPart!,
        model,
        baseURL: process.env.EMBEDDING_BASE_URL ?? 'https://api.openai.com/v1',
        apiKey: process.env.EMBEDDING_API_KEY ?? process.env.OPENAI_API_KEY ?? '',
        dimension: 1024,
      }
  }
}

program.parse()
